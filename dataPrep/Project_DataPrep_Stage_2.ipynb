{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZp7zWgqcEA9"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import calmap\n",
        "import os\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files_by_country(dir_name, country_code):\n",
        "    try:\n",
        "        json_file = os.path.join(dir_name, f\"{country_code}_category_id.json\")\n",
        "        csv_file = os.path.join(dir_name, f\"{country_code}_youtube_trending_data.csv\")\n",
        "\n",
        "        with open(json_file, 'r', encoding='utf-8') as json_data:\n",
        "            json_content = json.load(json_data)\n",
        "            # print(f\"Contents of {json_file}:\")\n",
        "            # print(json_content)\n",
        "\n",
        "        # for japanese\n",
        "        # videos = pd.read_csv(csv_file, encoding=\"latin\")\n",
        "        videos = pd.read_csv(csv_file)\n",
        "        # print(videos)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Files for {country_code} not found.\")\n",
        "\n",
        "    return json_content, videos\n",
        "\n",
        "country_code = 'RU'\n",
        "json_content, videos = read_files_by_country('/Users/<USERID>/Desktop/Data/archive2023', country_code)"
      ],
      "metadata": {
        "id": "-ycZyYwlcO5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos['description'] = videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "\n",
        "##converting dates and times and creating a new column for publish time\n",
        "\n",
        "videos['publishedAt'] = pd.to_datetime(videos['publishedAt'])\n",
        "videos['trending_date'] = pd.to_datetime(videos['trending_date'])\n",
        "videos.dropna(subset=['publishedAt'], inplace=True)\n",
        "videos.dropna(subset=['trending_date'], inplace=True)\n",
        "# videos.head()\n",
        "\n",
        "videos['publish_date'] = videos['publishedAt'].dt.date\n",
        "videos['publish_time'] = videos['publishedAt'].dt.time\n",
        "videos['trending_date'] = videos['trending_date'].dt.date\n"
      ],
      "metadata": {
        "id": "4-K4nvZocqT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "##creating new column which has the time until the video begins to trend\n",
        "\n",
        "json_df = pd.DataFrame(json_content['items'])\n",
        "# Convert 'id' column to int64\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "\n",
        "\n",
        "# Extract 'title' from 'snippet' and assign it a name\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "\n",
        "# Merge the DataFrames with the 'title' column\n",
        "videos = videos.merge(json_df[['id', 'category_title']], left_on='categoryId', right_on='id')\n",
        "\n",
        "# Drop the 'id' column from the merged DataFrame\n",
        "videos = videos.drop(columns=['id'])\n",
        "\n",
        "trending_repeat = videos.groupby(['video_id'])['category_title'].value_counts().reset_index(name='Trending Days')\n",
        "# trending_repeat.head()\n",
        "\n",
        "repeat_all = trending_repeat.pivot_table(index='Trending Days', columns='category_title', values='video_id', aggfunc='count').fillna(0)\n",
        "# repeat_all\n",
        "\n",
        "repeat_all_percentage = repeat_all.divide(repeat_all.sum(axis=1), axis=0) * 100\n",
        "# repeat_all_percentage.head()"
      ],
      "metadata": {
        "id": "Anm28q9KcscS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_trending = videos.groupby('video_id').size().reset_index(name='days_trending')\n",
        "# drop duplicates\n",
        "video_noduplicates = videos.drop_duplicates(subset='video_id', keep='first')\n",
        "merge_videos = pd.merge(video_noduplicates, sort_trending, on='video_id')"
      ],
      "metadata": {
        "id": "JqdF4uXrc1Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eoxYKgKWc2Pr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}