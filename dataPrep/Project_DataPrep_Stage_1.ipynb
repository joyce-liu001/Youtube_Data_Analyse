{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import calmap"
      ],
      "metadata": {
        "id": "W3lvzH4ibJmM"
      },
      "id": "W3lvzH4ibJmM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the CSV files (US, CA, DE, GB, FR, IN, JP, KR, MX, RU)\n",
        "files = [i for i in glob.glob('/Users/{Username}/Desktop/Data/1718/*.{}'.format('csv'))]\n",
        "sorted(files)"
      ],
      "metadata": {
        "id": "1Gqybxnzg4Sq"
      },
      "id": "1Gqybxnzg4Sq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = list()\n",
        "# add country column\n",
        "for csv in files:\n",
        "    df = pd.read_csv(csv,index_col='video_id', encoding=\"ISO-8859-1\")\n",
        "    df['country'] = csv[5:7]\n",
        "    dfs.append(df)\n",
        "video_df = pd.concat(dfs)\n",
        "video_df.head(3)"
      ],
      "metadata": {
        "id": "hHCe3qT7kPbE"
      },
      "id": "hHCe3qT7kPbE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling in empty spaces in the description column\n",
        "video_df['description'] = video_df['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "\n",
        "# converting dates and times and creating a new column for publish time\n",
        "video_df['trending_date'] = pd.to_datetime(video_df['trending_date'],errors='coerce', format='%y.%d.%m')\n",
        "video_df['publish_time'] = pd.to_datetime(video_df['publish_time'], errors='coerce', format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
        "\n",
        "video_df = video_df.dropna(how='any',inplace=False, axis = 0)\n",
        "\n",
        "video_df.insert(4, 'publish_date', video_df['publish_time'].dt.date)\n",
        "video_df['publish_time'] = video_df['publish_time'].dt.time\n",
        "video_df = video_df[video_df.index != '#NAME?']\n",
        "\n",
        "# full set of combined data, keep for later use\n",
        "df_full = video_df.reset_index().sort_values('trending_date').set_index('video_id')\n",
        "# which only keep the last entry if duplicated because it carries latest stat)\n",
        "video_df = video_df.reset_index().sort_values('trending_date').drop_duplicates('video_id',keep='last').set_index('video_id')\n",
        "df_full.tail()"
      ],
      "metadata": {
        "id": "dtwqlT2xkTeW"
      },
      "id": "dtwqlT2xkTeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## for 2017-2018 data\n",
        "videos['month_year'] = videos['trending_date'].apply(lambda x: f\"{x[0:2]}-{x[6:]}\")\n",
        "month_year = videos.groupby(['month_year'],as_index=False)['category_title'].value_counts().reset_index().sort_index()\n",
        "month_year = month_year.rename(columns={'category_title':'Category Title'})\n",
        "\n",
        "\n",
        "# Pivot data to get category counts per month\n",
        "pivot_df = month_year.pivot(index='month_year', columns='Category Title', values='count').fillna(0)"
      ],
      "metadata": {
        "id": "AVD87lrpnUs0"
      },
      "id": "AVD87lrpnUs0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CA_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/CAvideos.csv')\n",
        "\n",
        "#filling in empty spaces in the description column\n",
        "CA_videos['description'] = CA_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "\n",
        "##converting dates and times and creating a new column for publish time\n",
        "CA_videos['publish_date'] = pd.to_datetime(CA_videos['publish_time'].str[0:10])\n",
        "CA_videos['publish_time'] = pd.to_datetime(CA_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "CA_videos['trending_date'] = pd.to_datetime(CA_videos['trending_date'],format='%y.%d.%m')\n",
        "\n",
        "##creating new column which has the time until the video begins to trend\n",
        "CA_videos['days_til_trend']= ((CA_videos['trending_date'] - CA_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "DE_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/DEvideos.csv')\n",
        "DE_videos['description'] = DE_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "DE_videos['publish_date'] = pd.to_datetime(DE_videos['publish_time'].str[0:10])\n",
        "DE_videos['publish_time'] = pd.to_datetime(DE_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "DE_videos['trending_date'] = pd.to_datetime(DE_videos['trending_date'],format='%y.%d.%m')\n",
        "DE_videos['days_til_trend']= ((DE_videos['trending_date'] - DE_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "FR_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/FRvideos.csv')\n",
        "FR_videos['description'] = FR_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "FR_videos['publish_date'] = pd.to_datetime(FR_videos['publish_time'].str[0:10])\n",
        "FR_videos['publish_time'] = pd.to_datetime(FR_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "FR_videos['trending_date'] = pd.to_datetime(FR_videos['trending_date'],format='%y.%d.%m')\n",
        "FR_videos['days_til_trend']= ((FR_videos['trending_date'] - FR_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "GB_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/GBvideos.csv')\n",
        "GB_videos['description'] = GB_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "GB_videos['publish_date'] = pd.to_datetime(GB_videos['publish_time'].str[0:10])\n",
        "GB_videos['publish_time'] = pd.to_datetime(GB_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "GB_videos['trending_date'] = pd.to_datetime(GB_videos['trending_date'],format='%y.%d.%m')\n",
        "GB_videos['days_til_trend']= ((GB_videos['trending_date'] - GB_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "IN_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/INvideos.csv')\n",
        "IN_videos['description'] = IN_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "IN_videos['publish_date'] = pd.to_datetime(IN_videos['publish_time'].str[0:10])\n",
        "IN_videos['publish_time'] = pd.to_datetime(IN_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "IN_videos['trending_date'] = pd.to_datetime(IN_videos['trending_date'],format='%y.%d.%m')\n",
        "IN_videos['days_til_trend']= ((IN_videos['trending_date'] - IN_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "US_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/USvideos.csv')\n",
        "US_videos['description'] = US_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "US_videos['publish_date'] = pd.to_datetime(US_videos['publish_time'].str[0:10])\n",
        "US_videos['publish_time'] = pd.to_datetime(US_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "US_videos['trending_date'] = pd.to_datetime(US_videos['trending_date'],format='%y.%d.%m')\n",
        "US_videos['days_til_trend']= ((US_videos['trending_date'] - US_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "JP_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/JPvideos.csv', encoding=\"ISO-8859-1\")\n",
        "JP_videos['description'] = JP_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "JP_videos['publish_date'] = pd.to_datetime(JP_videos['publish_time'].str[0:10])\n",
        "JP_videos['publish_time'] = pd.to_datetime(JP_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "JP_videos['trending_date'] = pd.to_datetime(JP_videos['trending_date'],format='%y.%d.%m')\n",
        "JP_videos['days_til_trend']= ((JP_videos['trending_date'] - JP_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "KR_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/KRvideos.csv', encoding=\"ISO-8859-1\")\n",
        "KR_videos['description'] = KR_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "KR_videos['publish_date'] = pd.to_datetime(KR_videos['publish_time'].str[0:10])\n",
        "KR_videos['publish_time'] = pd.to_datetime(KR_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "KR_videos['trending_date'] = pd.to_datetime(KR_videos['trending_date'],format='%y.%d.%m')\n",
        "KR_videos['days_til_trend']= ((KR_videos['trending_date'] - KR_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "MX_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/MXvideos.csv', encoding=\"ISO-8859-1\")\n",
        "MX_videos['description'] = MX_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "MX_videos['publish_date'] = pd.to_datetime(MX_videos['publish_time'].str[0:10])\n",
        "MX_videos['publish_time'] = pd.to_datetime(MX_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "MX_videos['trending_date'] = pd.to_datetime(MX_videos['trending_date'],format='%y.%d.%m')\n",
        "MX_videos['days_til_trend']= ((MX_videos['trending_date'] - MX_videos['publish_date']).astype(int))/86400000000000\n",
        "\n",
        "\n",
        "RU_videos = pd.read_csv('/Users/<USERID>/Desktop/Data/2017-2018/RUvideos.csv', encoding=\"ISO-8859-1\")\n",
        "RU_videos['description'] = RU_videos['description'].apply(lambda x: '' if pd.isnull(x)  else x)\n",
        "RU_videos['publish_date'] = pd.to_datetime(RU_videos['publish_time'].str[0:10])\n",
        "RU_videos['publish_time'] = pd.to_datetime(RU_videos['publish_time'].str[11:19], format='%H:%M:%S')\n",
        "RU_videos['trending_date'] = pd.to_datetime(RU_videos['trending_date'],format='%y.%d.%m')\n",
        "RU_videos['days_til_trend']= ((RU_videos['trending_date'] - RU_videos['publish_date']).astype(int))/86400000000000"
      ],
      "metadata": {
        "id": "0TzPIXjdbKlP"
      },
      "id": "0TzPIXjdbKlP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###using category titles from json\n",
        "\n",
        "# manually open and read the JSON file\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/CA_category_id.json', 'r') as json_file:\n",
        "    CA_category_id = json.load(json_file)\n",
        "\n",
        "json_df = pd.DataFrame(CA_category_id['items'])\n",
        "# Convert 'id' column to int64\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "\n",
        "# Extract 'title' from 'snippet' and assign it a name\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "\n",
        "# Merge the DataFrames with the 'title' column\n",
        "CA_videos = CA_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "\n",
        "# Drop the 'id' column from the merged DataFrame\n",
        "CA_videos = CA_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/DE_category_id.json', 'r') as json_file:\n",
        "    DE_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(DE_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "DE_videos = DE_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "DE_videos = DE_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/FR_category_id.json', 'r') as json_file:\n",
        "    FR_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(FR_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "FR_videos = FR_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "FR_videos = FR_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/GB_category_id.json', 'r') as json_file:\n",
        "    GB_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(GB_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "GB_videos = GB_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "GB_videos = GB_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/IN_category_id.json', 'r') as json_file:\n",
        "    IN_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(IN_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "IN_videos = IN_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "IN_videos = IN_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/US_category_id.json', 'r') as json_file:\n",
        "    US_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(US_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "US_videos = US_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "US_videos = US_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/JP_category_id.json', 'r') as json_file:\n",
        "    JP_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(JP_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "JP_videos = JP_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "JP_videos = JP_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/KR_category_id.json', 'r') as json_file:\n",
        "    KR_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(KR_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "KR_videos = KR_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "KR_videos = KR_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/MX_category_id.json', 'r') as json_file:\n",
        "    MX_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(MX_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "MX_videos = MX_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "MX_videos = MX_videos.drop(columns=['id'])\n",
        "\n",
        "with open('/Users/<USERID>/Desktop/Data/2017-2018/RU_category_id.json', 'r') as json_file:\n",
        "    RU_category_id = json.load(json_file)\n",
        "json_df = pd.DataFrame(RU_category_id['items'])\n",
        "json_df['id'] = json_df['id'].astype('int64')\n",
        "json_df['category_title'] = json_df['snippet'].apply(lambda x: x['title'])\n",
        "RU_videos = RU_videos.merge(json_df[['id', 'category_title']], left_on='category_id', right_on='id')\n",
        "RU_videos = RU_videos.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "jR_CdWEWegPB"
      },
      "id": "jR_CdWEWegPB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}